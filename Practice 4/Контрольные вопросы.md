## Контрольные вопросы  

### 1. Чем отличаются типы памяти в CUDA и в каких случаях их использовать?
Глобальная память используется для хранения больших массивов данных, но имеет высокую задержку. Разделяемая память применяется для быстрого обмена данными между потоками одного блока. Локальная память используется для временных переменных внутри потока и отличается высокой скоростью доступа.

### 2. Как использование разделяемой памяти влияет на производительность?
Разделяемая память позволяет значительно сократить число обращений к медленной глобальной памяти. Это уменьшает задержки доступа и повышает общую производительность параллельного алгоритма.

### 3. Доступ и как его обеспечить?
Корректный доступ обеспечивается с помощью синхронизации потоков (__syncthreads) и атомарных операций. Это предотвращает состояния гонки при одновременном доступе к общим данным.

### 4. Какие сложности возникают при работе с большим объемом данных на GPU?
Основные сложности связаны с ограниченным объемом быстрой памяти, высокой стоимостью доступа к глобальной памяти и необходимостью правильной организации потоков и блоков для эффективного использования ресурсов GPU.

### 5. Почему важно минимизировать доступ к глобальной памяти?
Глобальная память имеет высокую задержку по сравнению с другими типами памяти. Частые обращения к ней существенно замедляют выполнение программы, поэтому важно использовать разделяемую и локальную память там, где это возможно.

### 6. Как использовать профилирование для анализа производительности CUDA-программ?
Для анализа производительности применяются инструменты профилирования CUDA (например, NVIDIA Nsight). Они позволяют измерять время выполнения ядер, количество обращений к памяти и выявлять узкие места в программе.
