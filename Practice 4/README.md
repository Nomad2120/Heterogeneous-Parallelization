# Практическая работа №4 
## Тема  
Оптимизация параллельного кода на GPU с использованием различных типов памяти.
## Цель работы  
Изучить и на практике применить различные типы памяти CUDA (глобальную, разделяемую и локальную) для оптимизации параллельных вычислений на GPU, а также сравнить их влияние на производительность.

## Что сделано в работе  
Вся практическая часть реализована **в одном файле practice4.cu**, логически разделённом на части.

### 1. Подготовка данных
- Генерируется массив случайных чисел.
- Размеры массивов для тестирования:
  - 10 000  
  - 100 000  
  - 1 000 000  

### 2. Редукция суммы элементов массива
Реализованы два варианта параллельной редукции:

- **Редукция с использованием только глобальной памяти**  
  Используется atomicAdd для суммирования всех элементов массива.
- **Редукция с использованием глобальной и разделяемой памяти**  
  Внутри каждого блока выполняется редукция в shared memory, после чего сумма блока добавляется в глобальную сумму одним атомарным действием.
Для обоих вариантов измеряется время выполнения и проверяется корректность результата.

### 3. Оптимизация сортировки на GPU
Реализована комбинированная сортировка:
- пузырьковая сортировка небольших подмассивов (чанков) с использованием **локальной памяти**;
- хранение общего массива в **глобальной памяти**;
- поэтапное слияние отсортированных подмассивов:
  - через **разделяемую память** для малых сегментов;
  - через **глобальную память** для больших сегментов.

После сортировки проверяется корректность результата.

### 4. Измерение производительности
- Замер времени редукции и сортировки для всех размеров массивов.
- Результаты выводятся в формате CSV:
На основе CSV построены графики зависимости времени выполнения от размера массива.

## Среда выполнения
- **Google Colab**
- GPU: NVIDIA Tesla T4
