## Контрольные вопросы

### 1. Какие основные типы памяти существуют в архитектуре CUDA и чем они отличаются по скорости доступа?
В CUDA используются глобальная, разделяемая, локальная и регистровая память. Самая быстрая — регистровая, затем разделяемая. Глобальная память имеет наибольшую задержку, но доступна всем потокам.

### 2. В каких случаях использование разделяемой памяти позволяет ускорить выполнение CUDA-программы?
Разделяемая память эффективна, когда данные многократно используются потоками одного блока. Она снижает количество обращений к глобальной памяти и уменьшает задержки доступа.

### 3. Как шаблон доступа к глобальной памяти влияет на производительность GPU-программы?
При коалесцированном доступе обращения потоков объединяются в меньшее количество транзакций памяти, что ускоряет выполнение. Некоалесцированный доступ приводит к большему числу операций чтения и снижает производительность.

### 4. Почему одинаковый алгоритм на GPU может показывать разное время выполнения при разных способах обращения к памяти?
Потому что разные способы доступа по-разному используют пропускную способность памяти. Даже при одинаковых вычислениях неэффективный доступ к памяти может значительно замедлить выполнение.

### 5. Как размер блока потоков влияет на производительность CUDA-ядра?
Размер блока влияет на количество активных варпов и загрузку вычислительных блоков GPU. Слишком маленькие блоки недоиспользуют GPU, слишком большие могут ограничивать число активных блоков.

### 6. Что такое варп и почему важно учитывать его при разработке CUDA-программ?
Варп — это группа из 32 потоков, выполняющихся синхронно. Если потоки внутри варпа идут по разным веткам, возникает дивергенция, которая снижает производительность.

### 7. Какие факторы необходимо учитывать при выборе конфигурации сетки и блоков потоков?
Необходимо учитывать размер задачи, число потоков, архитектуру GPU, использование памяти и количество активных варпов. Цель — максимально загрузить GPU без лишних простоев.

### 8. Почему оптимизация CUDA-программы часто начинается с анализа работы с памятью, а не с изменения алгоритма?
Потому что большинство CUDA-программ ограничены пропускной способностью памяти. Оптимизация доступа к памяти часто даёт больший выигрыш, чем усложнение алгоритма..
